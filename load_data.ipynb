{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sparkify Data\n",
    "\n",
    "This notebook contains the first step of the Sparkify project. First, it loads the medium-sized Sparkify dataset from video.udacity-data.com into the local directory using the `curl` command below. Second, it loads the medium-sized dataset (462MB) and the mini dataset (128MB) which should be added manually to `/data` into a Cloud Storage bucket.\n",
    "\n",
    "The additional notebooks `run_exploratory_data_analysis.ipynb` and `run_pipe_sparkify` read the data directly from Cloud Storage, because according to the [official doc](https://spark.apache.org/docs/latest/rdd-programming-guide.html#external-datasets):\n",
    "\n",
    "> If using a path on the local filesystem, the file must also be accessible at the same path on worker nodes. Either copy the file to all workers or use a network-mounted shared file system.\n",
    "\n",
    "## Requirements\n",
    "1. The directory `/data` must exist.\n",
    "2. The file `mini_sparkify_event_data.json` must be present in the `/data` directory.\n",
    "3. The notebook must be executed from a PySpark kernel.\n",
    "4. In the folder `/authentication`, there must be a file `gcp_client_secrets.json` with secrets to access GCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/home/Sparkify-churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(project_dir)\n",
    "from data_transfer import transfer_files_with_cloud_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"pyspark-cluster-202205\"\n",
    "file_path_mini = \"data/mini_sparkify_event_data.json\"\n",
    "file_path_medium = \"data/medium_sparkify_event_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  231M  100  231M    0     0  43.8M      0  0:00:05  0:00:05 --:--:-- 47.9M\n"
     ]
    }
   ],
   "source": [
    "# load the medium Sparkify dataset into local dir\n",
    "!curl \"https://video.udacity-data.com/topher/2018/December/5c1d6681_medium-sparkify-event-data/medium-sparkify-event-data.json\" >> file_path_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading '/home/Sparkify-churn/data/mini_sparkify_event_data.json' to GCP bucket 'pyspark-cluster-202205' as 'data/mini_sparkify_event_data.json'...\n",
      "Done.\n",
      "\n",
      "Uploading '/home/Sparkify-churn/data/medium_sparkify_event_data.json' to GCP bucket 'pyspark-cluster-202205' as 'data/medium_sparkify_event_data.json'...\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the medium Sparkify dataset from local dir to Cloud Storage\n",
    "for file_path in [file_path_mini]:#, file_path_medium]:\n",
    "    transfer_files_with_cloud_storage(\n",
    "        bucket_name=bucket_name,\n",
    "        local_file_name=os.path.join(project_dir, file_path),\n",
    "        remote_blob_name=file_path,\n",
    "        transfer_option=\"export\",\n",
    "        project_dir=project_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
